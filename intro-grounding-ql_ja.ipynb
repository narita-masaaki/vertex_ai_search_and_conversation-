{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8d47e2-d301-4b46-a703-71f10731dcbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3449c9-de0a-4289-8e8e-e917745109d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Getting Started with Grounding in Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a5d72a-6355-443b-af80-c8e7f93cb8dc",
   "metadata": {},
   "source": [
    "**Note**: このノートブックは、[Generative AI](https://github.com/GoogleCloudPlatform/generative-ai) リポジトリの [Vertex AI での Grounding の開始方法](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/grounding/intro-grounding.ipynb) ノートブックから改変したもので、Google Cloud Skills Boost 演習のコンテキスト内で実行されるように設計されています。\n",
    "\n",
    "## 概要\n",
    "\n",
    "[Vertex AI での Grounding](https://cloud.google.com/vertex-ai/docs/generative-ai/grounding/ground-language-models) を使用すると、言語モデル (例: [`gemini-1.5-pro`](https://cloud.google.com/vertex-ai/docs/generative-ai/language-model-overview)) を使用して、独自のドキュメントとデータに基づいたコンテンツを生成できます。この機能により、モデルは実行時にトレーニング データを超える情報にアクセスできます。[Vertex AI Agent Builder](https://cloud.google.com/generative-ai-app-builder/docs/enterprise-search-introduction) 内のモデル応答データ ストアをグラウンディングすることで、データにグラウンディングされた LLM は、より正確で最新の関連性の高い応答を生成できます。\n",
    "\n",
    "グラウンディングには次の利点があります:\n",
    "\n",
    "- モデルの幻覚 (モデルが事実に基づかないコンテンツを生成するインスタンス) を削減します\n",
    "- モデルの応答を特定の情報、ドキュメント、およびデータ ソースに固定します\n",
    "- 生成されたコンテンツの信頼性、精度、および適用性を強化します\n",
    "\n",
    "Vertex AI のグラウンディングのコンテキストでは、[Vertex AI Agent Builder のデータ ストア](https://cloud.google.com/generative-ai-app-builder/docs/create-datastore-ingest) を構成できます。これには、ウェブサイト データ、非構造化データ、または構造化データの形式で独自のデータを含めることができます"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1987f448-7e14-4fb2-8354-5c775e03b00c",
   "metadata": {},
   "source": [
    "## 始める前に\n",
    "\n",
    "このノートブックは、[Vertex AI Workbench インスタンス](https://cloud.google.com/vertex-ai/docs/workbench/instances/introduction) 環境で実行するように作成されています。\n",
    "\n",
    "### インストール\n",
    "\n",
    "このノートブックを実行するには、必要な `google-cloud-aiplatform` パッケージをインストールします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e72873-3d2a-4991-b0a8-710f54c0add5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911af2f9-0625-4778-989b-fb6427454d40",
   "metadata": {
    "tags": []
   },
   "source": [
    "パッケージをインストールした後、カーネルを再起動します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa6dc28-3dfa-405b-834d-d30d008df78f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e365f27a-45a4-4984-a416-f0e5c7b6dcf5",
   "metadata": {},
   "source": [
    "**Note**: 上記のセルを実行すると、「`intro-grounding-ql.ipynb のカーネルが停止したようです。自動的に再起動します`」というメッセージが表示されます。これはカーネルの再起動による意図された動作です。次のセルでノートブックの作業を続行できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3e9ed6-f520-4bd3-a2fd-8738b9fe6608",
   "metadata": {},
   "source": [
    "### プロジェクトIDとリージョンを設定する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112ba8f9-42bd-4ba5-b4c1-d10ad90827dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This function retrieves the project ID value set in the Workbench Instance environment.\n",
    "def get_project_id():\n",
    "    project_list = !gcloud config get-value project \n",
    "    return project_list[0]\n",
    "\n",
    "PROJECT_ID = get_project_id()\n",
    "REGION = \"us-central1\"\n",
    "\n",
    "print(f'Project ID: {PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e894dc40-5147-42f3-839c-16edfbfe2fc5",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3a0719-c733-429e-a205-60f16a67cd6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import vertexai\n",
    "from vertexai.generative_models import (\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Tool,\n",
    "    grounding,\n",
    ")\n",
    "from vertexai.preview.generative_models import grounding as preview_grounding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e80af8-5a25-4a6b-8c58-ced29239fba8",
   "metadata": {},
   "source": [
    "### 接地された Gemini 出力の可読性を向上させるヘルパー関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04bb1b1-86de-4dca-8c08-ec1a2cf9f0aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_grounding_response(response: GenerationResponse):\n",
    "    \"\"\"Prints Gemini response with grounding citations.\"\"\"\n",
    "    grounding_metadata = response.candidates[0].grounding_metadata\n",
    "\n",
    "    # Citation indices are in byte units\n",
    "    ENCODING = \"utf-8\"\n",
    "    text_bytes = response.text.encode(ENCODING)\n",
    "\n",
    "    prev_index = 0\n",
    "    markdown_text = \"\"\n",
    "\n",
    "    for grounding_support in grounding_metadata.grounding_supports:\n",
    "        text_segment = text_bytes[\n",
    "            prev_index : grounding_support.segment.end_index\n",
    "        ].decode(ENCODING)\n",
    "\n",
    "        footnotes_text = \"\"\n",
    "        for grounding_chunk_index in grounding_support.grounding_chunk_indices:\n",
    "            footnotes_text += f\"[{grounding_chunk_index + 1}]\"\n",
    "\n",
    "        markdown_text += f\"{text_segment} {footnotes_text}\\n\"\n",
    "        prev_index = grounding_support.segment.end_index\n",
    "\n",
    "    if prev_index < len(text_bytes):\n",
    "        markdown_text += str(text_bytes[prev_index:], encoding=ENCODING)\n",
    "\n",
    "    markdown_text += \"\\n----\\n## Grounding Sources\\n\"\n",
    "\n",
    "    if grounding_metadata.web_search_queries:\n",
    "        markdown_text += (\n",
    "            f\"\\n**Web Search Queries:** {grounding_metadata.web_search_queries}\\n\"\n",
    "        )\n",
    "        if grounding_metadata.search_entry_point:\n",
    "            markdown_text += f\"\\n**Search Entry Point:**\\n {grounding_metadata.search_entry_point.rendered_content}\\n\"\n",
    "    elif grounding_metadata.retrieval_queries:\n",
    "        markdown_text += (\n",
    "            f\"\\n**Retrieval Queries:** {grounding_metadata.retrieval_queries}\\n\"\n",
    "        )\n",
    "\n",
    "    markdown_text += \"### Grounding Chunks\\n\"\n",
    "\n",
    "    for index, grounding_chunk in enumerate(\n",
    "        grounding_metadata.grounding_chunks, start=1\n",
    "    ):\n",
    "        context = grounding_chunk.web or grounding_chunk.retrieved_context\n",
    "        if not context:\n",
    "            print(f\"Skipping Grounding Chunk {grounding_chunk}\")\n",
    "            continue\n",
    "\n",
    "        markdown_text += f\"{index}. [{context.title}]({context.uri})\\n\"\n",
    "\n",
    "    display(Markdown(markdown_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb606912-155d-495a-b2c4-7987d518ff6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Vertex AI SDK と Vertex AI からの生成モデルを初期化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a78517-263b-4957-8887-c6500173f353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "model = GenerativeModel(\"gemini-1.5-pro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580f6768-1819-4613-b167-aa5c09e757dc",
   "metadata": {},
   "source": [
    "# 例: カスタム ドキュメントとデータによるグラウンディング\n",
    "\n",
    "この例では、グラウンディングなしの LLM レスポンスと、[Vertex AI Search のデータストアの結果](https://cloud.google.com/generative-ai-app-builder/docs/create-datastore-ingest) でグラウンディングされたレスポンスを比較します。BigQuery クエリ内で Gemini を使用する方法について質問します。\n",
    "\n",
    "**`DATA_STORE_ID` 変数の値は、ラボで先ほど作成したデータストアの ID に置き換えてください。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba44987-cf52-4c0b-bd80-ffa3ca542aa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_STORE_ID = \"google-cloud-website_<some_numbers>\"  # Replace this with your data store ID from Vertex AI Search!\n",
    "DATA_STORE_REGION = \"global\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c34a440-fcc7-4c14-bf5a-91e15de520ba",
   "metadata": {},
   "source": [
    "ここで、BigQuery のオブジェクト テーブルとその使用タイミングについて質問してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086d775d-8a63-46ba-ba42-1f57bd8efea6",
   "metadata": {},
   "source": [
    "### グラウンディングなしのテキスト生成\n",
    "\n",
    "グラウンディングなしで LLM に予測リクエストを送信します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8add0e-10d0-43df-8104-120939105eb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROMPT = \"BigQuery SQL クエリで Gemini を使用するにはどうすればよいですか?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21e0842-3c32-4dd8-b725-e84dd6e7b13a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = model.generate_content(PROMPT)\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f05b46-a3ac-4bae-968e-efbf7878c962",
   "metadata": {},
   "source": [
    "### Vertex AI 検索結果に基づいたテキスト生成\n",
    "\n",
    "これで、`tools` キーワード引数に `grounding.VertexAISearch()` というグラウンディング ツールを追加して、最初にカスタム データ ストア内で検索を実行し、次に関連ドキュメントに基づいて回答を作成するように LLM に指示できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63c876c-700e-42b9-a99c-f7ac7c42355f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tool = Tool.from_retrieval(\n",
    "    preview_grounding.Retrieval(\n",
    "        preview_grounding.VertexAISearch(\n",
    "            datastore=DATA_STORE_ID,\n",
    "            project=PROJECT_ID,\n",
    "            location=DATA_STORE_REGION,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "response = model.generate_content(\n",
    "    PROMPT,\n",
    "    tools=[tool],\n",
    ")\n",
    "\n",
    "print_grounding_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31edf263-c94e-4c8a-bd6c-7cef14e2b33a",
   "metadata": {},
   "source": [
    "根拠のない応答には、BigQuery での Gemini の使用に関する LLM からの限られた情報しか含まれておらず、正確ではない可能性があることに注意してください。一方、Vertex AI Search の結果に基づいた応答には、BigQuery に関する Google Cloud ドキュメントからの最新情報が含まれています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda31f62-a6dd-43ac-a930-c187c324f818",
   "metadata": {},
   "source": [
    "## 例: グラウンディングされたチャット応答\n",
    "\n",
    "Vertex AI でチャット モデルを操作するときにもグラウンディングを使用できます。この例では、グラウンディングのない LLM 応答と、Google 検索の結果と Vertex AI Search のデータ ストアにグラウンディングされた応答を比較します。\n",
    "\n",
    "Vertex AI に関する質問をし、続いて Vertex AI で管理されているデータセットに関する質問をします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b7030a-e4a6-4225-ba10-3a82d9656896",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROMPT = \"Vertex AI の管理対象データセットとは何ですか?\"\n",
    "PROMPT_FOLLOWUP = \"どのようなタイプのデータを使用できますか\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15b2857-c2a0-4d24-8af5-ff23f829f2cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat = model.start_chat()\n",
    "\n",
    "response = chat.send_message(PROMPT)\n",
    "display(Markdown(response.text))\n",
    "\n",
    "response = chat.send_message(PROMPT_FOLLOWUP)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e905c0-c8c7-484f-b04c-6a3430211e4c",
   "metadata": {},
   "source": [
    "### Vertex AI 検索結果に基づいたチャット セッション\n",
    "\n",
    "これで、`grounding_source` キーワード引数に `GroundingSource.VertexAISearch()` のグラウンディング ソースを追加して、チャット モデルに最初にカスタム データ ストア内で検索を実行し、次に関連ドキュメントに基づいて回答を作成するように指示できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c53a1bc-c5f9-4715-b604-b37e230855ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat = model.start_chat()\n",
    "tool = Tool.from_retrieval(\n",
    "    preview_grounding.Retrieval(\n",
    "        preview_grounding.VertexAISearch(\n",
    "            datastore=DATA_STORE_ID,\n",
    "            project=PROJECT_ID,\n",
    "            location=DATA_STORE_REGION,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "response = chat.send_message(PROMPT, tools=[tool])\n",
    "print_grounding_response(response)\n",
    "\n",
    "response = chat.send_message(PROMPT_FOLLOWUP, tools=[tool])\n",
    "print_grounding_response(response)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
